{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03adc55-b03e-4783-905c-521d93f30e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvariational_diffusion_cdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mastro_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_astro_data\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvariational_diffusion_cdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_figure,compute_pk\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcomet_ml\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/variational_diffusion_cdm/model/utils/utils.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      9\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/PycharmProjects/bccp/variational_diffusion_cdm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norms, boxsize\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkl_std_normal\u001b[39m(mean_squared, var):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (var \u001b[38;5;241m+\u001b[39m mean_squared \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(var\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-15\u001b[39m)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.expanduser('~'))\n",
    "from variational_diffusion_cdm.data.astro_dataset import get_astro_data\n",
    "from variational_diffusion_cdm.model.utils.utils import draw_figure,compute_pk\n",
    "import comet_ml\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch import autograd, Tensor\n",
    "from lightning.pytorch import LightningModule, Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import CometLogger\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from typing import Optional, Tuple\n",
    "from torch.special import expm1\n",
    "from tqdm import trange\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf88a75-0950-4fa4-a76d-a76585d1031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(7)\n",
    "cropsize = 256\n",
    "batch_size = 12\n",
    "num_workers = 8\n",
    "   \n",
    "dataset = 'Astrid'\n",
    "learning_rate = 1e-3 #1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230542c6-bc89-4258-96b8-39e68f53b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = get_astro_data(\n",
    "        dataset,\n",
    "        num_workers=num_workers,\n",
    "        # resize=cropsize,\n",
    "        batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3378576-ac88-44d9-8bd1-d6e2da2b3294",
   "metadata": {},
   "source": [
    "print(np.shape(dm.train_data), len(dm.valid_data),len(dm.test_data))\n",
    "one_batch = next(iter( dm.train_dataloader()))\n",
    "print(np.shape(one_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b128171-c8d7-49a5-9035-8e42a9510e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # the first convolutional layer, followed by batch normalization,\n",
    "        # and then the ReLU activation function\n",
    "        #input (12, 1, 256, 256) --> (12, 64, 256, 256)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, padding_mode='circular'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # second convolutional layer has a similar sequence\n",
    "        # (12, 64, 256, 256) --> (12, 128, 128, 128)\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # (12, 128, 128, 128) --> (12, 64, 256, 256)\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # (12, 64, 256, 256) --> (12, 1, 256, 256)\n",
    "        self.output_layer = nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=1) \n",
    "\n",
    "\n",
    "    # this is the forward pass!\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.downsample(out)\n",
    "        out = self.upsample(out)\n",
    "        out = self.output_layer(out, output_size=x.size())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f08152-7505-428a-9665-2906bfb5e250",
   "metadata": {},
   "source": [
    " \"one_batch = next(iter( dm.train_dataloader()))\\n\",\n",
    "    \"conditioning, x = one_batch\\n\",\n",
    "    \"print(f'input: {np.shape(conditioning)}, output: {np.shape(x)}')\\n\",\n",
    "    \"model = SimpleNet()\\n\",\n",
    "    \"model = model.eval()\\n\",\n",
    "    \"out_1 = model.conv1(conditioning)\\n\",\n",
    "    \"print(f'out_layer1:{np.shape(out_1)}')\\n\",\n",
    "    \"out_2 = model.downsample(out_1)\\n\",\n",
    "    \"print(f'out_layer2:{np.shape(out_2)}')\\n\",\n",
    "    \"out_3 = model.upsample(out_2)\\n\",\n",
    "    \"print(f'out_layer2:{np.shape(out_3)}')\\n\",\n",
    "    \"final = model.output_layer(out_3)\\n\",\n",
    "    \"print(f'final_layer:{np.shape(final)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913457e-1b86-4bcc-b0bb-f840c96ef7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float = 3.0e-4,\n",
    "        weight_decay: float = 1.0e-5,\n",
    "        n_sampling_steps: int = 250,\n",
    "        draw_figure=None,\n",
    "        dataset='illustris',\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"draw_figure\"])\n",
    "        \n",
    "        self.model= SimpleNet() #ResnetGenerator(1,1) #SimpleNet()\n",
    "        self.dataset=dataset\n",
    "        print(\"suite:\", self.dataset)\n",
    "        self.draw_figure=draw_figure\n",
    "        if self.draw_figure is None:\n",
    "            def draw_figure(args,**kwargs):\n",
    "                fig=plt.figure(figsize=(5,5))\n",
    "                return fig\n",
    "            self.draw_figure=draw_figure\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def evaluate(self, batch: Tuple, stage: str = None) -> Tensor:\n",
    "\n",
    "        cdm_map, true_map = batch\n",
    "        mtot_pred = self(cdm_map)\n",
    "        loss = mse_loss(mtot_pred, true_map)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        batch: Tuple,\n",
    "        batch_idx: int,\n",
    "    ) -> Tensor:\n",
    "        return self.evaluate(batch, \"train\")\n",
    "\n",
    "\n",
    "    def validation_step(self, batch: Tuple, batch_idx: int) -> Tensor:\n",
    "        \"\"\"validate model\n",
    "\n",
    "        Args:\n",
    "            batch (Tuple): batch of examples\n",
    "            batch_idx (int): idx for batch\n",
    "\n",
    "        Returns:\n",
    "            Tensor: loss\n",
    "        \"\"\"\n",
    "        conditioning, x = batch    \n",
    "        loss = 0    \n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            sample = self(conditioning)\n",
    "            loss = mse_loss(x, sample)\n",
    "            fig = self.draw_figure(x,sample,conditioning,self.dataset)\n",
    "            self.log_dict({'val_loss': loss}, on_epoch=True)\n",
    "            if self.logger is not None:\n",
    "                self.logger.experiment.log_figure(figure=fig)\n",
    "            plt.close()\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.evaluate(batch, \"test\")\n",
    "        if self.logger is not None:\n",
    "            self.logger.log_metrics({\"test_loss\": loss.mean()})\n",
    "        return self.evaluate(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer=optimizer,\n",
    "            T_0=10,\n",
    "\n",
    "        )\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a91a1f6-3abe-4904-b42f-170a62b87d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = BasicCNN(\n",
    "        dataset=dataset,\n",
    "        learning_rate=learning_rate,\n",
    "        image_shape=(1,cropsize,cropsize),\n",
    "        draw_figure=draw_figure,\n",
    "    )\n",
    "    # Checkpoint every time val_loss improves\n",
    "val_checkpoint = ModelCheckpoint(\n",
    "        filename=\"{epoch}-{step}-{val_loss:.3f}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "    # Checkpoint at every 6000 steps\n",
    "latest_checkpoint = ModelCheckpoint(\n",
    "        filename=\"latest-{epoch}-{step}\",\n",
    "        monitor=\"step\",\n",
    "        mode=\"max\",\n",
    "        every_n_train_steps=60, #6000\n",
    "        save_top_k=10\n",
    "    )\n",
    "\n",
    "comet_logger = CometLogger(\n",
    "            api_key=os.environ.get(\"COMET_API_KEY\"),\n",
    "            project_name=\"baryonize_DM\",\n",
    "            experiment_name='SimpleCNN',\n",
    "        )\n",
    "\n",
    "trainer = Trainer(\n",
    "        logger=comet_logger,\n",
    "        accelerator=\"auto\",\n",
    "        max_epochs=10, #1000\n",
    "        gradient_clip_val=0.5,\n",
    "        callbacks=[LearningRateMonitor(),\n",
    "                    latest_checkpoint,\n",
    "                    val_checkpoint],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d0014-00b9-437e-a77d-b1a6dcb901e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=cnn, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650d003-3b3d-47b5-8237-e983d8658662",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = trainer.test(model=cnn, datamodule=dm)\n",
    "\n",
    "trainer.logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3b03a-1f33-497f-b307-0474f190525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b5655-cc50-493d-b970-33363c042c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = '/Users/link/PycharmProjects/bccp/baryonize_DM/8ad6ca35ce4d4f029b73dccbbe16282e/checkpoints/epoch=9-step=10000-val_loss=0.019.ckpt'\n",
    "state_dict=torch.load(ckpt)[\"state_dict\"]\n",
    "cnn.load_state_dict(state_dict)\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6541cb-f9af-4a74-9c03-0b5939c29bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioning, x =  next(iter(dm.test_dataloader()))   #ValueError: too many values to unpack (expected 2)\n",
    "with torch.no_grad():\n",
    "    sample = cnn(conditioning)\n",
    "fig = draw_figure(x,sample,conditioning,cnn.dataset)\n",
    "fig.savefig('/Users/link/PycharmProjects/bccp/test_IllustrisTNG_1P.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99876757-7ed4-47c2-b7be-ad4d0593acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(dm.test_data), np.shape(next(iter(dm.test_dataloader())) ), np.shape(next(iter(dm.train_dataloader())) )) #(2100, 2, 1, 256, 256) (2, 100, 1, 256, 256) (2, 12, 1, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae37acb-d2f5-4db0-a45a-7c5b5c3d6ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff6a51-4c99-402d-a2ac-4534578311a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewEnvironment1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
